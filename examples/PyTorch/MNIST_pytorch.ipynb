{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.3/293.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.25 in /Users/Ryder/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from seaborn) (1.5.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /Users/Ryder/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from seaborn) (3.6.0)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /Users/Ryder/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from seaborn) (1.23.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/Ryder/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/Ryder/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (21.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/Ryder/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/Ryder/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/Ryder/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/Ryder/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/Ryder/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.37.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/Ryder/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/Ryder/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from pandas>=0.25->seaborn) (2022.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/Ryder/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.12.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.15.1-cp310-cp310-macosx_11_0_arm64.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: requests in /Users/Ryder/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from torchvision) (2.28.1)\n",
      "Collecting torch==2.0.0\n",
      "  Downloading torch-2.0.0-cp310-none-macosx_11_0_arm64.whl (55.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/Ryder/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from torchvision) (1.23.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/Ryder/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/Ryder/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (4.3.0)\n",
      "Requirement already satisfied: networkx in /Users/Ryder/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (2.8.7)\n",
      "Requirement already satisfied: filelock in /Users/Ryder/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (3.8.0)\n",
      "Collecting jinja2\n",
      "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /Users/Ryder/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/Ryder/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from requests->torchvision) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/Ryder/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/Ryder/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from requests->torchvision) (2022.9.24)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/Ryder/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from jinja2->torch==2.0.0->torchvision) (2.1.1)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, jinja2, torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.1\n",
      "    Uninstalling torch-1.12.1:\n",
      "      Successfully uninstalled torch-1.12.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytorch-forecasting 0.10.3 requires torch<2.0,>=1.7, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed jinja2-3.1.2 mpmath-1.3.0 sympy-1.11.1 torch-2.0.0 torchvision-0.15.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting concretedropout\n",
      "  Downloading concretedropout-0.2.1-py3-none-any.whl (9.8 kB)\n",
      "Installing collected packages: concretedropout\n",
      "Successfully installed concretedropout-0.2.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install seaborn\n",
    "!{sys.executable} -m pip install torchvision\n",
    "!{sys.executable} -m pip install concretedropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "\n",
    "import torch\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.nn import functional as F\n",
    "\n",
    "PATH_DATASETS = os.environ.get(\"PATH_DATASETS\", \".\")\n",
    "BATCH_SIZE = 256 if torch.cuda.is_available() else 64\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "from concretedropout.pytorch import ConcreteDropout, ConcreteDropout2D, get_weight_regularizer, get_dropout_regularizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model and utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(LightningModule):\n",
    "    def __init__(self, weight_regularizer, dropout_regularizer):\n",
    "        super().__init__()\n",
    "\n",
    "        self.weight_regularizer = weight_regularizer\n",
    "        self.dropout_regularizer = dropout_regularizer\n",
    "\n",
    "        self.data_dir = PATH_DATASETS\n",
    "\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307,), (0.3081,)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=\"same\")\n",
    "        self.cd1 = ConcreteDropout2D(weight_regularizer=self.weight_regularizer, dropout_regularizer=self.dropout_regularizer)\n",
    "        self.maxpool1 = nn.MaxPool2d(2)\n",
    "        self.activation1 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=\"same\")\n",
    "        self.cd2 = ConcreteDropout2D(weight_regularizer=self.weight_regularizer, dropout_regularizer=self.dropout_regularizer)\n",
    "        self.maxpool2 = nn.MaxPool2d(2)\n",
    "        self.activation2 = nn.ReLU()\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.l1 = torch.nn.Linear(7 * 7*64, 10)\n",
    "\n",
    "        self.val_accuracy = Accuracy()\n",
    "        self.test_accuracy = Accuracy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cd1(x, self.conv1)\n",
    "        x = self.activation1(x)\n",
    "        x = self.maxpool1(x)\n",
    "\n",
    "        x = self.cd2(x, self.conv2)\n",
    "        x = self.activation2(x)\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.l1(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "        \n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        \n",
    "        reg = torch.zeros(1)\n",
    "        for module in filter(lambda x: isinstance(x, ConcreteDropout), self.modules()):\n",
    "            reg += module.regularization\n",
    "\n",
    "        loss = F.nll_loss(logits, y) + reg\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.val_accuracy.update(preds, y)\n",
    "\n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", self.val_accuracy, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.test_accuracy.update(preds, y)\n",
    "\n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(\"test_acc\", self.test_accuracy, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.02)\n",
    "\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download\n",
    "        MNIST(self.data_dir, train=True, download=True)\n",
    "        MNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=BATCH_SIZE, num_workers=4)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=BATCH_SIZE, num_workers=4)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=BATCH_SIZE, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wr = get_weight_regularizer(55000, l=1e-2, tau=0.1) # tau and l may need tuning, depending on the dataset\n",
    "dr = get_dropout_regularizer(55000, tau=0.1, cross_entropy_loss=True)\n",
    "\n",
    "mnist_model = MNISTModel(wr, dr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/Ryder/.pyenv/versions/3.10.6/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1789: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    accelerator=\"cpu\",\n",
    "    devices=1 if torch.cuda.is_available() else None,  # limiting got iPython runs\n",
    "    max_epochs=3,\n",
    "    callbacks=[TQDMProgressBar(refresh_rate=20)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:01<00:00, 9408924.02it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 9174166.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 8504842.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 10325489.85it/s]\n",
      "Missing logger folder: /Users/Ryder/Code/ai-trader/ConcreteDropout/examples/PyTorch/lightning_logs\n",
      "\n",
      "   | Name          | Type              | Params\n",
      "-----------------------------------------------------\n",
      "0  | conv1         | Conv2d            | 320   \n",
      "1  | cd1           | ConcreteDropout2D | 1     \n",
      "2  | maxpool1      | MaxPool2d         | 0     \n",
      "3  | activation1   | ReLU              | 0     \n",
      "4  | conv2         | Conv2d            | 18.5 K\n",
      "5  | cd2           | ConcreteDropout2D | 1     \n",
      "6  | maxpool2      | MaxPool2d         | 0     \n",
      "7  | activation2   | ReLU              | 0     \n",
      "8  | flatten       | Flatten           | 0     \n",
      "9  | l1            | Linear            | 31.4 K\n",
      "10 | val_accuracy  | Accuracy          | 0     \n",
      "11 | test_accuracy | Accuracy          | 0     \n",
      "-----------------------------------------------------\n",
      "50.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "50.2 K    Total params\n",
      "0.201     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0f944898774f0abf4761bf7480ad12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eebc6b86546043c1b33f3dc595d2f72a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d6e3fed399400db17a9c0d70f76ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5fdb323f36474993eeefb58318347d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "657d761bce52435b80da8624a0ca3998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(mnist_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /mnt/d/Aure/Documenti/Github/ConcreteDropout-TF2/examples/PyTorch/lightning_logs/version_0/checkpoints/epoch=2-step=645.ckpt\n",
      "Loaded model weights from checkpoint at /mnt/d/Aure/Documenti/Github/ConcreteDropout-TF2/examples/PyTorch/lightning_logs/version_0/checkpoints/epoch=2-step=645.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4bb72db7f4e4ca684abadc61ba26382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.9722999930381775\n",
      "        test_loss           0.0905378982424736\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.0905378982424736, 'test_acc': 0.9722999930381775}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(ckpt_path='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learned dropout probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00322718]\n",
      "[0.00941805]\n"
     ]
    }
   ],
   "source": [
    "for module in mnist_model.modules():\n",
    "    if isinstance(module, ConcreteDropout):\n",
    "        print(module.p.detach().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('3.10.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c9f78bc1c0d50e4ba4cbc46bfcf008359e29f3429e9b8900f5522f32e40ffad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
